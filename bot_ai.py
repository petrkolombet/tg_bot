# --- START OF FILE bot_ai.py ---

import logging
import asyncio
import json
import re
import google.generativeai as genai

import config

logger = logging.getLogger(__name__)

model = None
current_key_index = 0
API_KEYS = []

def init_ai(api_keys_list):
    global API_KEYS, current_key_index
    API_KEYS = api_keys_list
    current_key_index = 0
    return initialize_model()
    
def initialize_model():
    global model, current_key_index
    if not API_KEYS:
        logger.critical("‚ùå API_KEYS –ø—É—Å—Ç!")
        return False
    current_key = API_KEYS[current_key_index]
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: –æ—Ç–∫–ª—é—á–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    safety_settings = {
        'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',
        'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',
        'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE',
        'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE'
    }
    
    genai.configure(api_key=current_key, transport='rest')
    try:
        model = genai.GenerativeModel('gemini-flash-latest', safety_settings=safety_settings)
        logger.info(f"üîë –£—Å–ø–µ—à–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª—é—á–∞ #{current_key_index+1}")
        return True
    except Exception:
        try:
            model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings)
            logger.info(f"üîë –£—Å–ø–µ—à–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª—é—á–∞ #{current_key_index+1} —Å gemini-1.5-flash")
            return True
        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å: {e}")
            return False

def rotate_key():
    global current_key_index
    current_key_index = (current_key_index + 1) % len(API_KEYS)
    logger.warning("‚ö†Ô∏è –ú–µ–Ω—è—é API –∫–ª—é—á...")
    return initialize_model()

def clean_json_response(text):
    match = re.search(r'\{.*\}', text, re.DOTALL)
    return match.group(0).strip() if match else text.strip()

async def safe_generate_content(prompt, temperature=0.85):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–∑–æ–≤–∞ Gemini API.
    """
    global model
    logger.info(f"üì§ [GEMINI] –û—Ç–ø—Ä–∞–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª–∏–Ω–æ–π: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
    config_gen = genai.types.GenerationConfig(temperature=temperature)
    
    for _ in range(len(API_KEYS) + 1):
        if not model:
            logger.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.")
            return None
        try:
            loop = asyncio.get_running_loop()
            response = await loop.run_in_executor(None, lambda: model.generate_content(prompt, generation_config=config_gen))
            
            if not response.candidates:
                block_reason = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                if response.prompt_feedback:
                    block_reason = response.prompt_feedback.block_reason.name
                logger.error(f"‚ùå [GEMINI] –û—Ç–≤–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω! –ü—Ä–∏—á–∏–Ω–∞: {block_reason}")
                raise ValueError(f"Blocked: {block_reason}")
                
            return response
        except Exception as e:
            logger.error(f"‚ùå [GEMINI] –û—à–∏–±–∫–∞ API —Å –∫–ª—é—á–æ–º #{current_key_index+1}: {e}", exc_info=False)
            if not rotate_key():
                logger.critical("‚ùå [GEMINI] –í—Å–µ –∫–ª—é—á–∏ –Ω–µ—Ä–∞–±–æ—á–∏–µ.")
                return None
    return None

async def try_parse_or_repair_json(raw_response_obj):
    if not raw_response_obj: return None
    
    text_content = ""
    try:
        text_content = raw_response_obj.text
    except ValueError:
        logger.warning("‚ö†Ô∏è [JSON] –û—Ç–≤–µ—Ç API –ø—É—Å—Ç (–Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞). –ü—Ä–æ–ø—É—Å–∫–∞—é.")
        return None
    except Exception as e:
        logger.error(f"‚ö†Ô∏è [JSON] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        return None
        
    if not text_content: return None

    try:
        return json.loads(clean_json_response(text_content))
    except (json.JSONDecodeError, AttributeError, ValueError):
        logger.warning(f"‚ö†Ô∏è [JSON] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞. –ó–∞–ø—É—Å–∫–∞—é –ê–≤–∞—Ä–∏–π–Ω–æ–µ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ JSON.")
        repair_prompt = f"–û—Ç–≤–µ—Ç AI —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫—É –≤ JSON. –ò—Å–ø—Ä–∞–≤—å –µ–≥–æ. –í–ê–ñ–ù–û: –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –ø–æ–ª–µ 'replies': ['—Ç–µ–∫—Å—Ç']. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–ª–µ 'text' –¥–ª—è –æ—Ç–≤–µ—Ç–∞. –í–æ—Ç –Ω–µ—Ä–∞–±–æ—á–∏–π –æ—Ç–≤–µ—Ç:\n\n{text_content}"
        repaired_response = await safe_generate_content(repair_prompt, temperature=0.0)
        
        if repaired_response:
            try:
                repaired_text = repaired_response.text
                repaired_json = json.loads(clean_json_response(repaired_text))
                logger.info("‚úÖ [JSON] –ê–≤–∞—Ä–∏–π–Ω–æ–µ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ JSON —É—Å–ø–µ—à–Ω–æ!")
                return repaired_json
            except Exception:
                 logger.error(f"‚ùå [JSON] –ê–≤–∞—Ä–∏–π–Ω–æ–µ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ù–ï —É–¥–∞–ª–æ—Å—å.")
    return None

async def retrieve_memory(user_query, query_topic, state_manager):
    logger.info(f"üß† [MEMORY] –ó–∞–ø—É—â–µ–Ω –ø—Ä–æ—Ü–µ—Å—Å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ —Ç–µ–º–µ: '{query_topic}'")
    
    reflection_history = state_manager.state.get("reflection_history", [])
    keywords = query_topic.split()
    
    scored_messages = []
    for msg in reflection_history:
        score = sum(1 for keyword in keywords if keyword.lower() in msg['content'].lower())
        if score > 0: scored_messages.append((score, msg))
            
    scored_messages.sort(key=lambda x: x[0], reverse=True)
    relevant_context = [msg for score, msg in scored_messages[:20]]
    memory_packet_text = "\n".join([f"{m['role']}: {m['content']}" for m in relevant_context])
    
    memory_context = f"–í–ù–ò–ú–ê–ù–ò–ï! –≠—Ç–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –∑–∞–¥–∞—á–∞. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç —Ç–µ–±—è —á—Ç–æ-—Ç–æ –≤—Å–ø–æ–º–Ω–∏—Ç—å. –í–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏:\n---\n{memory_packet_text}\n---\n–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: '{user_query}'. –°–ª–µ–¥—É–π —Å–≤–æ–µ–º—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä—É. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç, —á–µ—Å—Ç–Ω–æ –ø—Ä–∏–∑–Ω–∞–π—Å—è."
    
    return await process_user_input(user_query, state_manager, memory_context=memory_context)

async def generate_reflection(state_manager):
    logger.info("üí° [REFLECTION] –ó–∞–ø—É—Å–∫–∞—é –ø—Ä–æ—Ü–µ—Å—Å –≥–∏–±—Ä–∏–¥–Ω–æ–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏...")
    recent_history = state_manager.state["chat_history"][-40:]
    recent_history_text = "\n".join([f"{'–Æ–∑–µ—Ä' if m['role']=='user' else '–ë–æ—Ç'}: {m['content']}" for m in recent_history])
    
    reflection_history = state_manager.state["reflection_history"]
    if len(reflection_history) < 50: return []

    older_context_end_index = max(0, len(reflection_history) - len(recent_history))
    older_context_start_index = max(0, older_context_end_index - 200)
    older_context = reflection_history[older_context_start_index:older_context_end_index]
    older_context_text = "\n".join([f"{'–Æ–∑–µ—Ä' if m['role']=='user' else '–ë–æ—Ç'}: {m['content']}" for m in older_context])
    
    prompt = f'<SYSTEM_REFLECT>–¢—ã ‚Äî –ò–ò-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ù–∞–π–¥–∏ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ù–ï–î–ê–í–ù–ò–ú –∏ –°–¢–ê–†–´–ú –¥–∏–∞–ª–æ–≥–æ–º. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 1-2 "—Ñ–æ–Ω–æ–≤—ã–µ –º—ã—Å–ª–∏" (–Ω–∞–±–ª—é–¥–µ–Ω–∏—è, —à—É—Ç–∫–∏, —Ç–µ–º—ã –¥–ª—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞). –í–µ—Ä–Ω–∏ JSON-—Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫.</SYSTEM_REFLECT><RECENT_HISTORY>{recent_history_text}</RECENT_HISTORY><OLDER_CONTEXT>{older_context_text}</OLDER_CONTEXT><JSON_OUTPUT>{{"thoughts": ["—Ç–µ–∫—Å—Ç –º—ã—Å–ª–∏"]}}</JSON_OUTPUT>'
    
    raw_response_obj = await safe_generate_content(prompt, temperature=0.7)
    parsed = await try_parse_or_repair_json(raw_response_obj)
    return parsed.get("thoughts", []) if parsed else []

async def process_user_input(user_text, state_manager, memory_context=None):
    try:
        with open(config.PROMPT_FILE, 'r', encoding='utf-8') as f: 
            prompt_template = f.read()
    except FileNotFoundError:
        logger.error("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –§–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return {"replies": ["–æ—à–∏–±–∫–∞. –Ω–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —Å–≤–æ–µ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞."], "mood_shift": 0.0}
        
    system_alert = ""
    memory_context_block = ""
    task_execution_block = ""
    
    # --- –ö–õ–Æ–ß–ï–í–ê–Ø –õ–û–ì–ò–ö–ê: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–ò–ü–ê –í–•–û–î–ê ---
    is_system_trigger = "[SYSTEM_TRIGGER:" in user_text
    
    if is_system_trigger:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏ –∏ –æ—á–∏—â–∞–µ–º user_text, —á—Ç–æ–±—ã –±–æ—Ç –Ω–µ –ø—É—Ç–∞–ª —ç—Ç–æ —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º —é–∑–µ—Ä–∞
        clean_task_text = user_text.replace("[SYSTEM_TRIGGER:", "").replace("]", "").strip()
        task_execution_block = f"<TASK_EXECUTION>\n–ü–†–ò–®–õ–û –í–†–ï–ú–Ø –í–´–ü–û–õ–ù–ò–¢–¨ –ó–ê–î–ê–ß–£/–ù–ê–ü–û–ú–ò–ù–ê–ù–ò–ï:\n'{clean_task_text}'\n–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ–± —ç—Ç–æ–º –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å.\n</TASK_EXECUTION>"
        user_text = "" # –û—á–∏—Å—Ç–∫–∞ –≤–≤–æ–¥–∞, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ —Å–∏—Å—Ç–µ–º–Ω—ã–π –≤—ã–∑–æ–≤
        logger.info(f"‚öôÔ∏è [AI] –†–µ–∂–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {clean_task_text}")
    else:
        # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if memory_context:
            memory_context_block = f"<MEMORY_CONTEXT>\n{memory_context}\n</MEMORY_CONTEXT>"
        elif triggered_topic := state_manager.get_and_clear_pending_topic(user_text):
            system_alert = f"<SYSTEM_ALERT>–í–ù–ò–ú–ê–ù–ò–ï: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—Ç–æ—Ä–æ–π —Ä–∞–∑ –≤–µ—Ä–Ω—É–ª—Å—è –∫ —Ç–µ–º–µ '{', '.join(triggered_topic)}'. –ü—Ä–æ—è–≤–∏ –∏–Ω—Ç–µ—Ä–µ—Å.</SYSTEM_ALERT>"
        elif state_manager.is_offended():
            system_alert = "<SYSTEM_ALERT>–í–ù–ò–ú–ê–ù–ò–ï: –¢—ã –æ–±–∏–∂–µ–Ω. –û—Ç–≤–µ—á–∞–π —Ö–æ–ª–æ–¥–Ω–æ/–æ–¥–Ω–æ—Å–ª–æ–∂–Ω–æ, –ª–∏–±–æ –º–æ–ª—á–∏. –ï—Å–ª–∏ —é–∑–µ—Ä –∏–∑–≤–∏–Ω—è–µ—Ç—Å—è, –º–æ–∂–µ—à—å –ø—Ä–æ—Å—Ç–∏—Ç—å (`forgive: true`).</SYSTEM_ALERT>"
        
    mood_instr = state_manager.get_mood_instruction()
    history = "\n".join([f"{'–Æ–∑–µ—Ä' if m['role']=='user' else '–¢—ã'}: {m['content']}" for m in state_manager.state["chat_history"]])
    
    thoughts_block = ""
    if state_manager.state["background_thoughts"]:
        thoughts_text = "\n".join([f'- ({t["id"]}) {t["text"]}' for t in state_manager.state["background_thoughts"]])
        thoughts_block = f'<BACKGROUND_THOUGHTS>–¢–≤–æ–∏ —Ñ–æ–Ω–æ–≤—ã–µ –º—ã—Å–ª–∏. –ü–†–ê–í–ò–õ–û: –ï—Å–ª–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä –∑–∞—Ç—É—Ö–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–π –º—ã—Å–ª—å.\n–¢–≤–æ–∏ —Ç–µ–∫—É—â–∏–µ –º—ã—Å–ª–∏:\n{thoughts_text}</BACKGROUND_THOUGHTS>'
    
    existing_tasks_list = state_manager.state.get("task_list", [])
    existing_tasks_str = "\n".join([f"- [{t['priority']}] {t.get('text', '–±–µ–∑ —Ç–µ–º—ã')}" for t in existing_tasks_list])
    if not existing_tasks_str: existing_tasks_str = "–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç."
        
    prompt = prompt_template.format(
        memory_context_block=memory_context_block, 
        system_alert=system_alert, 
        msk_time=state_manager.get_msk_time_obj().strftime("%H:%M"), 
        mood_instr=mood_instr, 
        thoughts_block=thoughts_block, 
        history=history,
        task_execution_block=task_execution_block, # –í—Å—Ç–∞–≤–ª—è–µ–º –±–ª–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
        user_text=user_text, 
        existing_tasks=existing_tasks_str
    )
    
    raw_response_obj = await safe_generate_content(prompt)
    parsed_json = await try_parse_or_repair_json(raw_response_obj)
    
    if parsed_json: 
        logger.info(f"üì• [DECISION] {parsed_json}")
    return parsed_json